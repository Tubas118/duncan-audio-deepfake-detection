{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.configuration import RunDetails\n",
    "\n",
    "runDetail = RunDetails('config-mfcc.yml', 'ASVspoof-2019_2025-03-27-mfcc-check-1_large-batch')\n",
    "# runDetail = RunDetails('config-mfcc.yml', 'ASVspoof-2019_2025-03-27-mfcc-check-1_huge-batch')\n",
    "\n",
    "notebookName = 'audio-deepfake-detection-testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFilename = runDetail.configFilename\n",
    "runJobId = runDetail.jobId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import config.configuration as configuration\n",
    "from preprocessors.mel_spectrogram import MelSpectrogramPreprocessor\n",
    "from notebook_utils import notebookToPython\n",
    "from processors.basic_model_evaluation_processor import BasicModelEvaluationProcessor\n",
    "from readers.label_reader import readTrainingLabelsWithJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configuration.ConfigLoader(configFilename)\n",
    "\n",
    "notebookToPython(notebookName)\n",
    "job = config.getJobConfig(runJobId)\n",
    "\n",
    "import json\n",
    "prettyJson = json.dumps(job.__dict__, indent=4)\n",
    "print(f\"job: {prettyJson}\")\n",
    "\n",
    "if (job.newModelGenerated):\n",
    "    raise ValueError(\"This notebook is meant for testing. Select a job with a value for 'persisted-model' set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = MelSpectrogramPreprocessor()\n",
    "model = joblib.load(job.persistedModel)\n",
    "evaluationProc = BasicModelEvaluationProcessor(job, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDataPath = job.fullJoinFilePath(job.dataPathRoot, job.dataPathSuffix)\n",
    "labels = readTrainingLabelsWithJob(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processArrays(X, y):\n",
    "    _X = np.array(X)\n",
    "    _y = np.array(y)\n",
    "    evaluationProc.process(_X, _y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for filename, label in labels.items():\n",
    "    _X, _y = generator.extract_features_singleSource(job, fullDataPath, filename, label)\n",
    "    X.append(_X)\n",
    "    y.append(_y)\n",
    "\n",
    "    if (len(X) >= job.inputFileBatchSize):\n",
    "        processArrays(X, y)\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "if (len(X) > 0):\n",
    "    processArrays(X, y)\n",
    "\n",
    "print(\"\\n\")\n",
    "report = evaluationProc.reportSnapshot()\n",
    "evaluationProc.writeReportToFile(job.persistedModelResults, report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-deepfake-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
