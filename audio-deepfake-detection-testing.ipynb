{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.configuration import RunDetails\n",
    "\n",
    "# runDetail = RunDetails('config.yml', 'GitLab-eval-data')\n",
    "runDetail = RunDetails('config.yml', 'ASVspoof-2019_training_split069_epoch10')\n",
    "\n",
    "notebookName = 'audio-deepfake-detection-testing'\n",
    "plot_title_suffix = \"(Testing)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFilename = runDetail.configFilename\n",
    "runJobId = runDetail.jobId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import config.configuration as configuration\n",
    "from notebook_utils import notebookToPython\n",
    "from postprocessors.plot_confusion_matrix import PlotConfusionMatrix\n",
    "from postprocessors.plot_precision_recall_curve import PlotPrecisionRecallCurve\n",
    "from postprocessors.plot_roc_curve import PlotRocCurve\n",
    "from postprocessors.plot_spectrogram import PlotSpectrogram\n",
    "from preprocessors.abstract_preprocessor import AbstractPreprocessor\n",
    "from preprocessors.preprocessor_factory import PreprocessorFactory\n",
    "from processors.basic_model_evaluation_processor import BasicModelEvaluationProcessor\n",
    "from readers.label_reader import readTrainingLabelsWithJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configuration.ConfigLoader(configFilename)\n",
    "\n",
    "notebookToPython(notebookName)\n",
    "job = config.getJobConfig(runJobId)\n",
    "\n",
    "import json\n",
    "prettyJson = json.dumps(job.__dict__, indent=4)\n",
    "print(f\"job: {prettyJson}\")\n",
    "\n",
    "if (job.newModelGenerated):\n",
    "    raise ValueError(\"This notebook is meant for testing. Select a job with a value for 'persisted-model' set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(job.persistedModel)\n",
    "evaluationProc = BasicModelEvaluationProcessor(job, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_factory = PreprocessorFactory()\n",
    "preprocessor: AbstractPreprocessor = preproc_factory.newPreprocessor(job.preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDataPath = job.fullJoinFilePath(job.dataPathRoot, job.dataPathSuffix)\n",
    "labels = readTrainingLabelsWithJob(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model processing of extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processArrays(X, y):\n",
    "    _X = np.array(X)\n",
    "    _y = np.array(y)\n",
    "    evaluationProc.process(_X, _y, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_X_test = []\n",
    "preprocessed_filenames = []\n",
    "preprocessed_labels = []\n",
    "MAX_INDEX_PREPROCESS_X_TEST = 5\n",
    "TICK_MARK = 10000\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for filename, label in labels.items():\n",
    "    _X, _y = preprocessor.extract_features_singleSource(job, fullDataPath, filename, label)\n",
    "    X.append(_X)\n",
    "    y.append(_y)\n",
    "\n",
    "    if (len(preprocessed_X_test) < MAX_INDEX_PREPROCESS_X_TEST):\n",
    "        preprocessed_X_test.append(_X)\n",
    "        preprocessed_filenames.append(filename)\n",
    "        preprocessed_labels.append(label)\n",
    "\n",
    "    if (job.inputFileBatchSize != None and len(X) >= job.inputFileBatchSize):\n",
    "        processArrays(X, y)\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "    if (len(X) % TICK_MARK == 0):\n",
    "        print(f\"processing... {len(X)} - {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(X) > 0):\n",
    "    processArrays(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extract spectrogram samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Preprocessor: {job.preprocessor}\")\n",
    "\n",
    "plot_spectrogram = PlotSpectrogram()\n",
    "\n",
    "display_spectrogram_count = len(preprocessed_X_test)\n",
    "if (display_spectrogram_count > MAX_INDEX_PREPROCESS_X_TEST):\n",
    "    display_spectrogram_count = MAX_INDEX_PREPROCESS_X_TEST\n",
    "\n",
    "for idx in range(0, display_spectrogram_count):\n",
    "    filename = preprocessed_filenames[idx]\n",
    "    data = preprocessed_X_test[idx]\n",
    "    title = f\"{job.preprocessor}: {filename} ({idx + 1} of {display_spectrogram_count})\"\n",
    "    plot_spectrogram.plot(data, job, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram with and without \"power_to_db\" transformation applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareIdx = 0\n",
    "fullDataPath = job.fullJoinFilePath(job.dataPathRoot, job.dataPathSuffix)\n",
    "\n",
    "preproc_noExec_power_to_db: AbstractPreprocessor = preproc_factory.newPreprocessor(job.preprocessor, exec_power_to_db=False)\n",
    "X_test_noPowerToDb, _ = preproc_noExec_power_to_db.extract_features_singleSource(job, fullDataPath, preprocessed_filenames[compareIdx], preprocessed_labels[compareIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = preprocessed_filenames[compareIdx]\n",
    "plot_spectrogram.plot(preprocessed_X_test[compareIdx], job, f\"{job.preprocessor}: {filename} (with power_to_db)\")\n",
    "\n",
    "plot_spectrogram_noPowerToDb = PlotSpectrogram()\n",
    "plot_spectrogram_noPowerToDb.plot(X_test_noPowerToDb, job, f\"{job.preprocessor}: {filename} (without power_to_db)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluationProc.batchResults[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_TITLE = f\"{PlotConfusionMatrix.DEFAULT_TITLE} {plot_title_suffix}\"\n",
    "cm_plot = PlotConfusionMatrix()\n",
    "cm_plot.plotFromResults(results, job, CM_TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_TITLE = f\"{PlotRocCurve.DEFAULT_TITLE} {plot_title_suffix}\"\n",
    "roc_plot = PlotRocCurve()\n",
    "roc_plot.plotFromResults(results, RC_TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_TITLE = f\"{PlotPrecisionRecallCurve.DEFAULT_TITLE} {plot_title_suffix}\"\n",
    "roc_plot = PlotPrecisionRecallCurve()\n",
    "roc_plot.plotFromResults(results, PP_TITLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "report = evaluationProc.reportSnapshot()\n",
    "evaluationProc.writeReportToFile(job.persistedModelResults, report)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing export of HTML when job complete\n",
    "# !jupyter nbconvert --execute --to html audio-deepfake-detection-testing.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-deepfake-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
