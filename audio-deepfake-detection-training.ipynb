{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.configuration import RunDetails\n",
    "\n",
    "# runDetail = RunDetails('config.yml', 'GitLab-training-data')\n",
    "runDetail = RunDetails('config.yml', 'ASVspoof-2019_training')\n",
    "# runDetail = RunDetails('config.yml', 'ASVspoof-2019_training_epoch-100')\n",
    "\n",
    "notebookName = 'audio-deepfake-detection-training'\n",
    "plot_title_suffix = \"(Training)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFilename = runDetail.configFilename\n",
    "runJobId = runDetail.jobId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config.configuration as configuration\n",
    "import model_definitions.model_cnn_definition as model_cnn_definition\n",
    "from postprocessors.plot_confusion_matrix import PlotConfusionMatrix\n",
    "from postprocessors.plot_roc_curve import PlotRocCurve\n",
    "from preprocessors.abstract_preprocessor import AbstractPreprocessor\n",
    "from preprocessors.preprocessor_factory import PreprocessorFactory\n",
    "from notebook_utils import notebookToPython\n",
    "from processors.basic_model_training_processor import BasicModelTrainingProcessor\n",
    "from processors.basic_model_evaluation_processor import BasicModelEvaluationProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configuration.ConfigLoader(configFilename)\n",
    "\n",
    "notebookToPython(notebookName)\n",
    "job = config.getJobConfig(runJobId)\n",
    "\n",
    "if (job.newModelGenerated == False):\n",
    "    raise ValueError(\"This notebook is meant for training. Select a job without a value for 'persisted-model' set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_factory = PreprocessorFactory()\n",
    "preprocessor: AbstractPreprocessor = preproc_factory.newPreprocessor(job.preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_encoded = preprocessor.extract_features_multipleSource(job, job.dataPathSuffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from config.configuration import Job\n",
    "from model_definitions.model_abstract_definition import ModelAbstractDefinition\n",
    "from processors.abstract_model_training_processor import AbstractModelTrainingProcessor\n",
    "\n",
    "# =============================================================================\n",
    "class BasicModelTrainingProcessor2(AbstractModelTrainingProcessor):\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    def __init__(self, job: Job, modelDefType):\n",
    "        super().__init__(job)\n",
    "        self.resetStatistics()\n",
    "        self.modelDefType = modelDefType\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    def resetStatistics(self):\n",
    "        self.jobStartTime = None\n",
    "        self.inputFileBatchCount = 0\n",
    "        self.inputFileCount = 0\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    def process(self, X, y_encoded, channels, test_size = 0.2, trainingSplitRandomState: int = None, \n",
    "                        scoring = 'accuracy'):\n",
    "        \n",
    "        if (self.jobStartTime == None):\n",
    "            self.jobStartTime = datetime.now(pytz.utc)\n",
    "\n",
    "        useTrainingSplitRandomState: int = self.__get_training_split_random_state__(trainingSplitRandomState)\n",
    "\n",
    "        print(f\"Selecting training and test data - traininSplitRandomState: {useTrainingSplitRandomState}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=test_size, random_state=useTrainingSplitRandomState)\n",
    "        \n",
    "        print(f\"Training using {len(X_train)} files.\")\n",
    "        model = self.__train_model__(X_train, X_test, y_train, y_test, channels, scoring)\n",
    "\n",
    "        return model, X_train, X_test, y_train, y_test\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    def reportSnapshot(self):\n",
    "        timestamp_utc = datetime.now(pytz.utc)\n",
    "        elapsed_time = timestamp_utc - self.jobStartTime\n",
    "        prettyJson = json.dumps(self.__job__.__dict__, indent=4)\n",
    "\n",
    "        report = f\"---- Training (start) ----\\n\"\n",
    "        report = report + f\"start time: {self.jobStartTime.isoformat()}\\n\"\n",
    "        report = report + f\"end time: {timestamp_utc.isoformat()}\\n\"\n",
    "        report = report + f\"elapsed: {elapsed_time}\\n\\n\"\n",
    "        report = report + f\"model file: {self.__job__.persistedModel}\\n\"\n",
    "        report = report + f\"batch count: {self.inputFileBatchCount}\\n\"\n",
    "        report = report + f\"file count: {self.inputFileCount}\\n\"\n",
    "        report = report + f\"job: {prettyJson}\\n\\n\"\n",
    "        report = report + f\"---- Training (end) ----\\n\"\n",
    "\n",
    "        return report\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    def __train_model__(self, X_train, X_test, y_train, y_test, channels, scoring) -> Model:\n",
    "        \n",
    "        modelDef: ModelAbstractDefinition = self.modelDefType(self.__job__, X_train.shape[2], channels)\n",
    "\n",
    "        model = modelDef.buildModel()\n",
    "        model.compile(optimizer=self.__job__.optimizer, loss=self.__job__.loss, metrics=self.__job__.metrics)\n",
    "\n",
    "        print(\"Training the Model...\")\n",
    "        model.fit(X_train, y_train, batch_size=self.__job__.batchSize, epochs=self.__job__.numEpochs, validation_data=(X_test, y_test))\n",
    "\n",
    "        print(f\"Saving model: {self.__job__.persistedModel}\")\n",
    "        joblib.dump(model, self.__job__.persistedModel)\n",
    "\n",
    "        # scores = cross_val_score(model, X_train, y_train, cv=self.__job__.cv, scoring=scoring)\n",
    "        # print(f\"cross validation scores: {scores}\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingProc = BasicModelTrainingProcessor2(job, model_cnn_definition.ModelCnnDefinition)\n",
    "model, X_train, X_test, y_train, y_test = trainingProc.process(X, y_encoded, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "kerasModel = KerasClassifier(build_fn=model, batch_size=job.batchSize, epochs=job.numEpochs,\n",
    "                             optimizer=job.optimizer, loss=job.loss, metrics=job.metrics)\n",
    "\n",
    "scores = cross_val_score(kerasModel, X_train, y_train, cv=job.cv)\n",
    "print(f\"cross validation scores: {scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationProc = BasicModelEvaluationProcessor(job, model)\n",
    "results = evaluationProc.process(X_test, y_test)\n",
    "print(f\"{results.reportSnaphot()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_TITLE = f\"{PlotConfusionMatrix.DEFAULT_TITLE} {plot_title_suffix}\"\n",
    "cm_plot = PlotConfusionMatrix()\n",
    "cm_plot.plotFromResults(results, job, CM_TITLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_TITLE = f\"{PlotRocCurve.DEFAULT_TITLE} {plot_title_suffix}\"\n",
    "roc_plot = PlotRocCurve()\n",
    "roc_plot.plotFromResults(results, RC_TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "report = evaluationProc.reportSnapshot(trainingProc)\n",
    "evaluationProc.writeReportToFile(job.persistedModelResults, report)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-deepfake-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
