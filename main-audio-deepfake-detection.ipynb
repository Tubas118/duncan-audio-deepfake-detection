{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import configuration\n",
    "from notebook_utils import notebookToPython\n",
    "from label_reader import readLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write python file\n"
     ]
    }
   ],
   "source": [
    "config = configuration.ConfigLoader('config.yml')\n",
    "\n",
    "notebookToPython(config.projectName)\n",
    "job = config.getJobConfig(config.activeJobId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:/Users/tubas/workspace/Deepfake/data/ASVspoof-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt...\n"
     ]
    }
   ],
   "source": [
    "trainingLabels = readLabels(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "fullDataPath = job.fullJoinFilePath(job.dataPath, job.trainingDataPath)\n",
    "\n",
    "for filename, label in trainingLabels.items():\n",
    "    audioSourceFilename = job.fullJoinFilePath(fullDataPath, filename + job.trainingDataExtension)\n",
    "    \n",
    "    audio, _ = librosa.load(audioSourceFilename, sr = job.sampleRate, duration = job.duration)\n",
    "\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y = audio, sr = job.sampleRate, n_mels = job.numMels)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    if (mel_spectrogram.shape[1] < job.maxTimeSteps):\n",
    "        padWidth = ((0, 0), (0, job.maxTimeSteps - mel_spectrogram.shape[1]))\n",
    "        mel_spectrogram = np.pad(array=mel_spectrogram, pad_width=padWidth, mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :job.maxTimeSteps]\n",
    "\n",
    "    X.append(mel_spectrogram)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y_encoded = to_categorical(y, job.numClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)    # test data is 20% of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model architecture\n",
    "input_shape = (job.numMels, X_train.shape[2], 1)  # Input shape for CNN (height, width, channels)\n",
    "model_input = Input(shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - why were these parameters selected? What purpose do they serve? Should they be configurable?\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(model_input)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "model_output = Dense(job.numClasses, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model_input, outputs=model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=job.optimizer, loss=job.loss, metrics=job.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 66ms/step - accuracy: 0.8861 - loss: 5.4227 - val_accuracy: 0.9102 - val_loss: 0.2121\n",
      "Epoch 2/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 0.9082 - loss: 0.2225 - val_accuracy: 0.9257 - val_loss: 0.2010\n",
      "Epoch 3/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9235 - loss: 0.1899 - val_accuracy: 0.9358 - val_loss: 0.1743\n",
      "Epoch 4/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.9356 - loss: 0.1644 - val_accuracy: 0.9468 - val_loss: 0.1527\n",
      "Epoch 5/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.9456 - loss: 0.1325 - val_accuracy: 0.9600 - val_loss: 0.1179\n",
      "Epoch 6/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 64ms/step - accuracy: 0.9590 - loss: 0.1072 - val_accuracy: 0.9651 - val_loss: 0.1060\n",
      "Epoch 7/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9670 - loss: 0.0836 - val_accuracy: 0.9608 - val_loss: 0.1186\n",
      "Epoch 8/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 65ms/step - accuracy: 0.9494 - loss: 0.1334 - val_accuracy: 0.9699 - val_loss: 0.0950\n",
      "Epoch 9/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 64ms/step - accuracy: 0.9777 - loss: 0.0576 - val_accuracy: 0.9807 - val_loss: 0.0718\n",
      "Epoch 10/10\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - accuracy: 0.9791 - loss: 0.0600 - val_accuracy: 0.9793 - val_loss: 0.0801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2228cf4ac30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.fit(X_train, y_train, batch_size=job.batchSize, epochs=job.numEpochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASVspoof-2019-1.libjob']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, job.persistedModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
